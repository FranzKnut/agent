# Agent

(TensorBoard [![Travis build status](https://www.travis-ci.com/tensorflow/tensorboard.svg?branch=master)](https://travis-ci.com/tensorflow/tensorboard/))

A Tensorboard plugin to explore reinforcement learning models at the timestep level. A project by Andrew Schreiber and [Fabian Steuer](https://github.com/fabiansteuer).

## Saliency heatmap demo

### Observations

The goal of the Atari game Enduro is to pass other cars without colliding. We've trained two models, one trained on 3000 episodes and the other trained on 10 episodes, which will be visualized using Agent.

The perturbation saliency heatmap below is generated by a process of measuring where blurs of the Atari frame produces a large change in what the model estimates the expected reward of the frame to be. Where you see **blue overlay is where the model is 'paying attention'**. See this paper for more [details](https://arxiv.org/pdf/1711.00138.pdf).

What do you notice from these 20 frames? (Advanced tip: download the gifs and step through each frame)

### 3,000 episodes of training

![Expert](https://user-images.githubusercontent.com/1892071/47758313-bae34980-dc67-11e8-8585-277a1b0bb4a2.gif)

### 10 episodes of training

![Noob](https://user-images.githubusercontent.com/1892071/47758314-bae34980-dc67-11e8-80c8-921d215ae474.gif)

One observation is that that the well-trained model adjusts itself substantially on the cars, especially when the agent's car coming close to passing another car. Meanwhile the untrainted model doesn't place much attention on the cars specifically, rather it's attention meanders randomly across the screen.

Why is this interesting? Perhaps it had turned out the well-trained model was barely paying attention to the cars at all. That would mean the 'expert' had learned some trick undiscernable to humans in it's environment, which may not generalize or be otherwise problematic from a safety perspective. A loss or averaged rewards graph would not permit you this insight; your metrics would simply tell you the model had learned well.

## Live example

### Updated Nov 26, 2018

http://li592-70.members.linode.com:6006/#agent

## Purpose / Musings

It's surprisingly difficult to understand **why** a reinforcement or inverse reinforcement learning agent makes a decision today.

At [distill.pub](distill.pub) we have seen impressive techniques and tooling emerge for interpreting supervised learning beyond summary statistics. Why do we find **a void of usable, open-source interpretability techniques for reinforcement learning**? Victoria Kraknova made a [well-reasoned call](https://www.youtube.com/watch?v=3HzIutdlpho) for more research in deep RL interpretability for AI Safety at a NIPS workshop a year ago. It seems there is much to be explored about why a RL agent choses actions **moment-by-moment** and that such work would be valuable for debugging and understanding, yet the subfield has published little since 2017. What is causing the paralysis?

We observe **a primary bottleneck is misfitted tooling**. From experience, the current process to extract and save the relevant network activations and episode frames is laborious and complex. Even if you succeed, the technique(s) you build tend to be tightly-coupled to your project (see [this group](https://arxiv.org/pdf/1602.02658.pdf) who made a compelling deep RL intepretability tool, but to use it you have to be _running their version of Lua and Windows 10_).

We find the above state of affairs frustrating for a [subfield of technical AI Safety](https://medium.com/@deepmindsafetyresearch/building-safe-artificial-intelligence-52f5f75058f1) potentially ripe with low-hanging fruit. We believe RL and IRL research would be **safer** if the field had a well-documented platform for intepreting agents using standard, popular tools (Unix, Python, Tensorflow, Tensorboard).

The purpose of Agent is to **accelerate progress in deep RL/IRL intepretability**. We are very interested in perspectives from people in the intepretability, deep RL/IRL, and AI Safety communities. Please share your feedback through [GitHub issues](https://github.com/andrewschreiber/agent/issues/new).

---

## Goals

Agent v0 targets Dec 1st with two deep learning interpretability techniques, [t-SNE](https://distill.pub/2016/misread-tsne/) and [saliency heatmaps](https://arxiv.org/abs/1711.00138), which we hope will prove immediately useful. v0 will include an API you can integrate into your new or existing RL model training code.

Agent v1 scope is still under development. For researchers with fresh insight into RL intepretability, Agent v1 aims to support **custom visualizations** with the aim to reduce the overhead in developing new techniques by an order of magnitude. Furthermore we aim for documentation and examples to make it straightforward to get started. Test coverage and a basic style guide for maintainability.

Agent was built in Python within Tensorboard due to the visualization suite's robustness and popularity among researchers. We hope someday Agent could be merged into Tensorboard itself like the [Beholder plugin](https://github.com/tensorflow/tensorboard/pull/613).

## Setup (Work in progress)

### Note: Agent is currently built for demonstration purposes.

Packages required (recommended version):

Python virtual environment (v3.6)

[Bazel](https://docs.bazel.build/versions/master/install.html) build tool from Google. Install guide in link. (v0.21.0)

Tensorflow (v1.13.1)

Then:

    git clone https://github.com/andrewschreiber/agent.git
    cd agent

    # Install API layer in your Python virtual environment
    pip install .

    #Build takes ~7m on a 2015 Macbook
    bazel build tensorboard:tensorboard

    #Use the custom tensorboard build by running
    ./bazel-bin/tensorboard/tensorboard --logdir tb/logdirectory/logs

### Tensorboard

To visualize training, use the following command to setup Baselines to
send tensorboard log files.

    export OPENAI_LOG_FORMAT='stdout,log,csv,tensorboard' OPENAI_LOGDIR=logs

Return to the original terminal tab, at the root of rlmonitor, and run your training:

    python -m baselines.run --alg=deepq --env=CartPole-v0 --save_path=./cartpole_model.pkl --num_timesteps=1e5

Go to the linked URL in the tensorboard tab to see your model train.

### Run Cartpole with DQN

    cd examples/baselines

Follow instuctions from https://github.com/andrewschreiber/baselines to
install Gym. Then:

Train a model:

    python -m baselines.run --alg=deepq --env=CartPole-v0 --save_path=./cartpole_model.pkl --num_timesteps=1e5

See the model playing Carptole:

<<<<<<< HEAD
python -m baselines.run --alg=deepq --env=CartPole-v0 --load_path=./cartpole_model.pkl --num_timesteps=0 --play
=======

### Text Dashboard

The Text Dashboard displays text snippets saved via `tf.summary.text`. Markdown
features including hyperlinks, lists, and tables are all supported.

# Frequently Asked Questions

### My TensorBoard isn't showing any data! What's wrong?

First, check that the directory passed to `--logdir` is correct. You can also
verify this by navigating to the Scalars dashboard (under the "Inactive" menu)
and looking for the log directory path at the bottom of the left sidebar.

If you're loading from the proper path, make sure that event files are present.
TensorBoard will recursively walk its logdir, it's fine if the data is nested
under a subdirectory. Ensure the following shows at least one result:

`find DIRECTORY_PATH | grep tfevents`

You can also check that the event files actually have data by running
tensorboard in inspect mode to inspect the contents of your event files.

`tensorboard --inspect --logdir DIRECTORY_PATH`

### TensorBoard is showing only some of my data, or isn't properly updating!

This issue usually comes about because of how TensorBoard iterates through the
`tfevents` files: it progresses through the events file in timestamp order, and
only reads one file at a time. Let's suppose we have files with timestamps `a`
and `b`, where `a<b`. Once TensorBoard has read all the events in `a`, it will
never return to it, because it assumes any new events are being written in the
more recent file. This could cause an issue if, for example, you have two
`FileWriters` simultaneously writing to the same directory. If you have
multiple summary writers, each one should be writing to a separate directory.

### Does TensorBoard support multiple or distributed summary writers?

No. TensorBoard expects that only one events file will be written to at a time,
and multiple summary writers means multiple events files. If you are running a
distributed TensorFlow instance, we encourage you to designate a single worker
as the "chief" that is responsible for all summary processing. See
[supervisor.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/supervisor.py)
for an example.

### I'm seeing data overlapped on itself! What gives?

If you are seeing data that seems to travel backwards through time and overlap
with itself, there are a few possible explanations.

- You may have multiple execution of TensorFlow that all wrote to the same log
  directory. Please have each TensorFlow run write to its own logdir.

- You may have a bug in your code where the global_step variable (passed
  to `FileWriter.add_summary`) is being maintained incorrectly.

- It may be that your TensorFlow job crashed, and was restarted from an earlier
  checkpoint. See _How to handle TensorFlow restarts_, below.

As a workaround, try changing the x-axis display in TensorBoard from `steps` to
`wall_time`. This will frequently clear up the issue.

### How should I handle TensorFlow restarts?

TensorFlow is designed with a mechanism for graceful recovery if a job crashes
or is killed: TensorFlow can periodically write model checkpoint files, which
enable you to restart TensorFlow without losing all your training progress.

However, this can complicate things for TensorBoard; imagine that TensorFlow
wrote a checkpoint at step `a`, and then continued running until step `b`, and
then crashed and restarted at timestamp `a`. All of the events written between
`a` and `b` were "orphaned" by the restart event and should be removed.

To facilitate this, we have a `SessionLog` message in
`tensorflow/core/util/event.proto` which can record `SessionStatus.START` as an
event; like all events, it may have a `step` associated with it. If TensorBoard
detects a `SessionStatus.START` event with step `a`, it will assume that every
event with a step greater than `a` was orphaned, and it will discard those
events. This behavior may be disabled with the flag
`--purge_orphaned_data false` (in versions after 0.7).

### How can I export data from TensorBoard?

The Scalar Dashboard supports exporting data; you can click the "enable
download links" option in the left-hand bar. Then, each plot will provide
download links for the data it contains.

If you need access to the full dataset, you can read the event files that
TensorBoard consumes by using the [`summary_iterator`](https://www.tensorflow.org/api_docs/python/tf/train/summary_iterator)
method.

### Can I customize which lines appear in a plot?

Using the [custom scalars plugin](tensorboard/plugins/custom_scalar), you can
create scalar plots with lines for custom run-tag pairs. However, within the
original scalars dashboard, each scalar plot corresponds to data for a specific
tag and contains lines for each run that includes that tag.

### Can I visualize margins above and below lines?

Margin plots (that visualize lower and upper bounds) may be created with the
[custom scalars plugin](tensorboard/plugins/custom_scalar). The original
scalars plugin does not support visualizing margins.

### Can I create scatterplots (or other custom plots)?

This isn't yet possible. As a workaround, you could create your custom plot in
your own code (e.g. matplotlib) and then write it into an `SummaryProto`
(`core/framework/summary.proto`) and add it to your `FileWriter`. Then, your
custom plot will appear in the TensorBoard image tab.

### Is my data being downsampled? Am I really seeing all the data?

TensorBoard uses [reservoir
sampling](https://en.wikipedia.org/wiki/Reservoir_sampling) to downsample your
data so that it can be loaded into RAM. You can modify the number of elements it
will keep per tag by using the `--samples_per_plugin` command line argument (ex:
`--samples_per_plugin=scalars=500,images=20`). Alternatively, you can change the
source code in
[tensorboard/backend/application.py](tensorboard/backend/application.py).
See this [StackOverflow question](http://stackoverflow.com/questions/43702546/tensorboard-doesnt-show-all-data-points/)
for some more information.

### I get a network security popup every time I run TensorBoard on a mac!

This is because by default, TensorBoard serves on host `0.0.0.0` which is
publicly accessible. You can stop the popups by specifying `--host localhost` at
startup.

### How can I contribute to TensorBoard development?

See [DEVELOPMENT.md](DEVELOPMENT.md).

### I have a different issue that wasn't addressed here!

First, try searching our [GitHub
issues](https://github.com/tensorflow/tensorboard/issues) and [Stack
Overflow][stack-overflow]. It may be
that someone else has already had the same issue or question.

General usage questions (or problems that may be specific to your local setup)
should go to [Stack Overflow][stack-overflow].

If you have found a bug in TensorBoard, please [file a GitHub issue](https://github.com/tensorflow/tensorboard/issues/new) with as much supporting
information as you can provide (e.g. attaching events files, including the output
of `tensorboard --inspect`, etc.).

[stack-overflow]: https://stackoverflow.com/questions/tagged/tensorboard

> > > > > > > 5fc3c8cea4b5f79c738345686a218f089b58ddba
